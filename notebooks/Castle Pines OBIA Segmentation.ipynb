{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load modules to process imagery\n",
    "import numpy as np\n",
    "import gdal\n",
    "import ogr\n",
    "from skimage import exposure\n",
    "from skimage.segmentation import quickshift\n",
    "from skimage.segmentation import slic\n",
    "import time\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from multiprocessing import Pool\n",
    "import workers\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load GeoTiff\n",
    "naip_fn = 'data/S3E115_clip.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bands 4 rows 10560 columns 10560\n",
      "(10560, 10560, 4)\n"
     ]
    }
   ],
   "source": [
    "#set driver for geotiff\n",
    "driverTiff = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "#open geotiff with gdal\n",
    "naip_ds = gdal.Open(naip_fn)\n",
    "\n",
    "#count the number of color bands in geotiff\n",
    "nbands = naip_ds.RasterCount\n",
    "\n",
    "#Create empty list\n",
    "band_data = []\n",
    "\n",
    "#export band numbers, and size of raster\n",
    "print('bands', naip_ds.RasterCount, 'rows', naip_ds.RasterYSize, 'columns', naip_ds.RasterXSize)\n",
    "\n",
    "#loop through the bands in nbands and append to empty band_data list\n",
    "for i in range(1, nbands+1):\n",
    "    band = naip_ds.GetRasterBand(i).ReadAsArray()\n",
    "    band_data.append(band)\n",
    "\n",
    "#stack arrays\n",
    "band_data = np.dstack(band_data)\n",
    "\n",
    "#export the shape of the data.  should match print statement above\n",
    "print(band_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale band data\n",
    "img = exposure.rescale_intensity(band_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create segments\n",
    "segments = slic(img, n_segments=500000, compactness=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save segments to raster\n",
    "segments_fn = 'data/segments_115.tif'\n",
    "segments_ds = driverTiff.Create(segments_fn, naip_ds.RasterXSize, naip_ds.RasterYSize, 1, gdal.GDT_Float32)\n",
    "segments_ds.SetGeoTransform(naip_ds.GetGeoTransform())\n",
    "segments_ds.SetProjection(naip_ds.GetProjectionRef())\n",
    "segments_ds.GetRasterBand(1).WriteArray(segments)\n",
    "segments_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids = np.unique(segments)\n",
    "objects = []\n",
    "\n",
    "for id in segment_ids:\n",
    "    object_features = workers.segment_features(img[segments == id])\n",
    "    objects.append(object_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0 max 7 mean 6.246771694214877e-05\n"
     ]
    }
   ],
   "source": [
    "# open the points file to use for training data\n",
    "train_fn = 'data/train_115.shp'\n",
    "train_ds = ogr.Open(train_fn)\n",
    "lyr = train_ds.GetLayer()\n",
    "\n",
    "# create a new raster layer in memory\n",
    "driver = gdal.GetDriverByName('MEM')\n",
    "target_ds = driver.Create('', naip_ds.RasterXSize, naip_ds.RasterYSize, 1, gdal.GDT_UInt16)\n",
    "target_ds.SetGeoTransform(naip_ds.GetGeoTransform())\n",
    "target_ds.SetProjection(naip_ds.GetProjection())\n",
    "\n",
    "# rasterize the training points\n",
    "options = ['ATTRIBUTE=id']\n",
    "gdal.RasterizeLayer(target_ds, [1], lyr, options=options)\n",
    "\n",
    "# retrieve the rasterized data and print basic stats\n",
    "data = target_ds.GetRasterBand(1).ReadAsArray()\n",
    "print('min', data.min(), 'max', data.max(), 'mean', data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class values [1 2 3 4 5 6 7]\n",
      "Training segments for class 1 : 229\n",
      "Training segments for class 2 : 238\n",
      "Training segments for class 3 : 86\n",
      "Training segments for class 4 : 525\n",
      "Training segments for class 5 : 432\n",
      "Training segments for class 6 : 147\n",
      "Training segments for class 7 : 123\n"
     ]
    }
   ],
   "source": [
    "ground_truth = target_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "classes = np.unique(ground_truth)[1:]\n",
    "print('class values', classes)\n",
    "\n",
    "segments_per_class = {}\n",
    "\n",
    "for klass in classes:\n",
    "    segments_of_class = segments[ground_truth == klass]\n",
    "    segments_per_class[klass] = set(segments_of_class)\n",
    "    print(\"Training segments for class\", klass, \":\", len(segments_of_class))\n",
    "\n",
    "intersection = set()\n",
    "accum = set()\n",
    "\n",
    "for class_segments in segments_per_class.values():\n",
    "    intersection |= accum.intersection(class_segments)\n",
    "    accum |= class_segments\n",
    "assert len(intersection) == 0, \"Segment(s) represent multiple classes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_img = np.copy(segments)\n",
    "threshold = train_img.max() + 1  # make the threshold value greater than any land cover class value\n",
    "\n",
    "# all pixels in training segments assigned value greater than threshold\n",
    "for klass in classes:\n",
    "    class_label = threshold + klass\n",
    "    for segment_id in segments_per_class[klass]:\n",
    "        train_img[train_img == segment_id] = class_label\n",
    " \n",
    "# training segments receive land cover class value, all other segments 0\n",
    "train_img[train_img <= threshold] = 0\n",
    "train_img[train_img > threshold] -= threshold\n",
    "\n",
    "# create objects and labels for training data\n",
    "training_objects = []\n",
    "training_labels = []\n",
    "for klass in classes:\n",
    "    class_train_object = [v for i, v in enumerate(objects) if segment_ids[i] in segments_per_class[klass]]\n",
    "    training_labels += [klass] * len(class_train_object)\n",
    "    training_objects += class_train_object\n",
    " \n",
    "classifier = RandomForestClassifier(n_jobs=-1)  # setup random forest classifier\n",
    "classifier.fit(training_objects, training_labels)  # fit rf classifier\n",
    "predicted = classifier.predict(objects)  # predict with rf classifier\n",
    "\n",
    "# create numpy array from rf classifiation and save to raster\n",
    "clf = np.copy(segments)\n",
    "for segment_id, klass in zip(segment_ids, predicted):\n",
    "    clf[clf == segment_id] = klass\n",
    " \n",
    "mask = np.sum(img, axis=2)  # this section masks no data values\n",
    "mask[mask > 0.0] = 1.0\n",
    "mask[mask == 0.0] = -1.0\n",
    "clf = np.multiply(clf, mask)\n",
    "clf[clf < 0] = -9999.0\n",
    " \n",
    "clfds = driverTiff.Create('data/classified_result_115.tif', naip_ds.RasterXSize, naip_ds.RasterYSize,\n",
    "                          1, gdal.GDT_Int16)  # this section saves to raster\n",
    "clfds.SetGeoTransform(naip_ds.GetGeoTransform())\n",
    "clfds.SetProjection(naip_ds.GetProjection())\n",
    "clfds.GetRasterBand(1).SetNoDataValue(-9999.0)\n",
    "clfds.GetRasterBand(1).WriteArray(clf)\n",
    "clfds = None\n",
    " \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
